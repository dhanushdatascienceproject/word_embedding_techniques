# -*- coding: utf-8 -*-
"""Word embedding Techniques.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p8VHMAPY2v5PDUHFnHWVICxD4j44H_pv

### Word Embedding Techniques using Embedding Layer in Keras
"""

### Libraries USed Tensorflow> 2.0  and keras

!pip install tensorflow-gpu

import tensorflow as tf
print(tf.__version__)

##tensorflow >2.0
from tensorflow.keras.preprocessing.text import one_hot



### sentences
sent=[  'the glass of milk',
     'the glass of juice',
     'the cup of tea',
    'I am a good boy',
     'I am a good developer',
     'understand the meaning of words',
     'your videos are good']

sent

### Vocabulary size
voc_size=500

"""#### One Hot Representation"""

onehot_repr=[one_hot(words,voc_size)for words in sent]
print(onehot_repr)

"""### Word Embedding Represntation"""

from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential

import numpy as np

## pre padding
sent_length=8
embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)
print(embedded_docs)

## 10 feature dimesnions
dim=10

model=Sequential()
model.add(Embedding(voc_size,10,input_length=sent_length))
model.compile('adam','mse')

model.summary()

##'the glass of milk',
embedded_docs[0]

model.predict(embedded_docs[0])

print(model.predict(embedded_docs))

embedded_docs[0]

print(model.predict(embedded_docs)[0])

### Assignment

sent=["The world is a better place",
      "Marvel series is my favourite movie",
      "I like DC movies",
      "the cat is eating the food",
      "Tom and Jerry is my favourite movie",
      "Python is my favourite programming language"
      ]